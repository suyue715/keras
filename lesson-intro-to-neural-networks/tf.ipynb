{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_boston,load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable(3, name='a')\n",
    "b = tf.Variable(4, name='b')\n",
    "f = tf.multiply(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result=f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target)\n",
    "\n",
    "y_train=y_train.reshape(-1,1)\n",
    "y_test=y_test.reshape(-1,1)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, X_train.shape[1]), name='X')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None), name='y')\n",
    "\n",
    "h1 = tf.layers.dense(X, 13, name='hidden1', activation=tf.nn.relu)\n",
    "y_hat = tf.layers.dense(h1, 1, activation=None)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y, y_hat)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(.01)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
    "        \n",
    "    pred = sess.run(y_hat, feed_dict={X: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 training loss 607.45 test loss 603.987\n",
      "epoch 2 training loss 600.238 test loss 597.069\n",
      "epoch 3 training loss 593.173 test loss 590.266\n",
      "epoch 4 training loss 586.212 test loss 583.596\n",
      "epoch 5 training loss 579.348 test loss 577.065\n",
      "epoch 6 training loss 572.588 test loss 570.644\n",
      "epoch 7 training loss 565.906 test loss 564.342\n",
      "epoch 8 training loss 559.302 test loss 558.157\n",
      "epoch 9 training loss 552.731 test loss 552.02\n",
      "epoch 10 training loss 546.177 test loss 545.906\n",
      "epoch 11 training loss 539.616 test loss 539.781\n",
      "epoch 12 training loss 533.022 test loss 533.655\n",
      "epoch 13 training loss 526.392 test loss 527.503\n",
      "epoch 14 training loss 519.723 test loss 521.315\n",
      "epoch 15 training loss 512.996 test loss 515.075\n",
      "epoch 16 training loss 506.178 test loss 508.777\n",
      "epoch 17 training loss 499.261 test loss 502.413\n",
      "epoch 18 training loss 492.222 test loss 495.975\n",
      "epoch 19 training loss 485.059 test loss 489.439\n",
      "epoch 20 training loss 477.757 test loss 482.805\n",
      "epoch 21 training loss 470.308 test loss 476.044\n",
      "epoch 22 training loss 462.706 test loss 469.157\n",
      "epoch 23 training loss 454.943 test loss 462.138\n",
      "epoch 24 training loss 447.025 test loss 454.97\n",
      "epoch 25 training loss 438.943 test loss 447.657\n",
      "epoch 26 training loss 430.693 test loss 440.211\n",
      "epoch 27 training loss 422.266 test loss 432.63\n",
      "epoch 28 training loss 413.661 test loss 424.913\n",
      "epoch 29 training loss 404.88 test loss 417.058\n",
      "epoch 30 training loss 395.928 test loss 409.052\n",
      "epoch 31 training loss 386.804 test loss 400.899\n",
      "epoch 32 training loss 377.516 test loss 392.584\n",
      "epoch 33 training loss 368.082 test loss 384.142\n",
      "epoch 34 training loss 358.511 test loss 375.579\n",
      "epoch 35 training loss 348.809 test loss 366.903\n",
      "epoch 36 training loss 338.998 test loss 358.118\n",
      "epoch 37 training loss 329.096 test loss 349.245\n",
      "epoch 38 training loss 319.117 test loss 340.287\n",
      "epoch 39 training loss 309.083 test loss 331.262\n",
      "epoch 40 training loss 299.011 test loss 322.19\n",
      "epoch 41 training loss 288.934 test loss 313.113\n",
      "epoch 42 training loss 278.877 test loss 304.052\n",
      "epoch 43 training loss 268.872 test loss 295.024\n",
      "epoch 44 training loss 258.942 test loss 286.055\n",
      "epoch 45 training loss 249.108 test loss 277.165\n",
      "epoch 46 training loss 239.406 test loss 268.381\n",
      "epoch 47 training loss 229.867 test loss 259.728\n",
      "epoch 48 training loss 220.533 test loss 251.219\n",
      "epoch 49 training loss 211.425 test loss 242.905\n",
      "epoch 50 training loss 202.57 test loss 234.807\n",
      "epoch 51 training loss 194.002 test loss 226.947\n",
      "epoch 52 training loss 185.745 test loss 219.347\n",
      "epoch 53 training loss 177.818 test loss 212.024\n",
      "epoch 54 training loss 170.238 test loss 204.985\n",
      "epoch 55 training loss 163.012 test loss 198.245\n",
      "epoch 56 training loss 156.144 test loss 191.807\n",
      "epoch 57 training loss 149.63 test loss 185.672\n",
      "epoch 58 training loss 143.472 test loss 179.837\n",
      "epoch 59 training loss 137.664 test loss 174.299\n",
      "epoch 60 training loss 132.191 test loss 169.051\n",
      "epoch 61 training loss 127.039 test loss 164.083\n",
      "epoch 62 training loss 122.194 test loss 159.382\n",
      "epoch 63 training loss 117.638 test loss 154.933\n",
      "epoch 64 training loss 113.35 test loss 150.715\n",
      "epoch 65 training loss 109.307 test loss 146.712\n",
      "epoch 66 training loss 105.48 test loss 142.909\n",
      "epoch 67 training loss 101.853 test loss 139.281\n",
      "epoch 68 training loss 98.4023 test loss 135.814\n",
      "epoch 69 training loss 95.1116 test loss 132.485\n",
      "epoch 70 training loss 91.9643 test loss 129.275\n",
      "epoch 71 training loss 88.9465 test loss 126.166\n",
      "epoch 72 training loss 86.0478 test loss 123.153\n",
      "epoch 73 training loss 83.2532 test loss 120.223\n",
      "epoch 74 training loss 80.5542 test loss 117.357\n",
      "epoch 75 training loss 77.9478 test loss 114.57\n",
      "epoch 76 training loss 75.4226 test loss 111.853\n",
      "epoch 77 training loss 72.9706 test loss 109.192\n",
      "epoch 78 training loss 70.5862 test loss 106.588\n",
      "epoch 79 training loss 68.2794 test loss 104.046\n",
      "epoch 80 training loss 66.0473 test loss 101.564\n",
      "epoch 81 training loss 63.8867 test loss 99.1376\n",
      "epoch 82 training loss 61.8029 test loss 96.7703\n",
      "epoch 83 training loss 59.7923 test loss 94.4629\n",
      "epoch 84 training loss 57.859 test loss 92.2181\n",
      "epoch 85 training loss 56.0055 test loss 90.0424\n",
      "epoch 86 training loss 54.2358 test loss 87.9461\n",
      "epoch 87 training loss 52.5521 test loss 85.9269\n",
      "epoch 88 training loss 50.9573 test loss 83.9819\n",
      "epoch 89 training loss 49.4394 test loss 82.11\n",
      "epoch 90 training loss 48.0008 test loss 80.2928\n",
      "epoch 91 training loss 46.6313 test loss 78.5491\n",
      "epoch 92 training loss 45.3318 test loss 76.8791\n",
      "epoch 93 training loss 44.0995 test loss 75.285\n",
      "epoch 94 training loss 42.9386 test loss 73.756\n",
      "epoch 95 training loss 41.847 test loss 72.2879\n",
      "epoch 96 training loss 40.8193 test loss 70.8876\n",
      "epoch 97 training loss 39.8444 test loss 69.5535\n",
      "epoch 98 training loss 38.9305 test loss 68.273\n",
      "epoch 99 training loss 38.0792 test loss 67.0383\n",
      "epoch 100 training loss 37.2889 test loss 65.8628\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
    "        train_loss = sess.run(loss, feed_dict={X: X_train, y: y_train})\n",
    "        test_loss = sess.run(loss, feed_dict={X: X_test, y: y_test})\n",
    "        print('epoch', epoch+1, 'training loss', train_loss, 'test loss', test_loss)\n",
    "    pred = sess.run(y_hat, feed_dict={X: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, X_train.shape[1]), name='X')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None), name='y')\n",
    "\n",
    "h1 = tf.layers.dense(X, 30, name='hidden1', activation=tf.nn.relu)\n",
    "y_hat = tf.layers.dense(h1, 1, name='y_hat', activation=tf.nn.sigmoid)\n",
    "\n",
    "loss = tf.losses.log_loss(y, y_hat)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(.01)\n",
    "\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        sess.run(training_op, feed_dict={X: X_train, y: y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-38f1ac3b6b4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "y = to_categorical(data.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, y)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9a14734a6682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "pred = sess.run(y_hat, feed_dict={X: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, X_train.shape[1]), name='X')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None), name='y')\n",
    "\n",
    "h1 = tf.layers.dense(X, 4, activation=tf.nn.relu, name='hidden1')\n",
    "y_hat = tf.layers.dense(h1, 3, name='y_hat', activation=None)\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(y, y_hat)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(.01)\n",
    "training_op = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must be same size: logits_size=[379,3] labels_size=[379,1]\n\t [[Node: softmax_cross_entropy_loss/xentropy = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](softmax_cross_entropy_loss/Reshape, softmax_cross_entropy_loss/Reshape_1)]]\n\nCaused by op 'softmax_cross_entropy_loss/xentropy', defined at:\n  File \"//anaconda/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"//anaconda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"//anaconda/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"//anaconda/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"//anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-f5e691258d88>\", line 9, in <module>\n    loss = tf.losses.softmax_cross_entropy(y, y_hat)\n  File \"//anaconda/lib/python3.5/site-packages/tensorflow/python/ops/losses/losses_impl.py\", line 529, in softmax_cross_entropy\n    name=\"xentropy\")\n  File \"//anaconda/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 1617, in softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"//anaconda/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2265, in _softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"//anaconda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"//anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"//anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[379,3] labels_size=[379,1]\n\t [[Node: softmax_cross_entropy_loss/xentropy = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](softmax_cross_entropy_loss/Reshape, softmax_cross_entropy_loss/Reshape_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must be same size: logits_size=[379,3] labels_size=[379,1]\n\t [[Node: softmax_cross_entropy_loss/xentropy = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](softmax_cross_entropy_loss/Reshape, softmax_cross_entropy_loss/Reshape_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1333309e140d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must be same size: logits_size=[379,3] labels_size=[379,1]\n\t [[Node: softmax_cross_entropy_loss/xentropy = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](softmax_cross_entropy_loss/Reshape, softmax_cross_entropy_loss/Reshape_1)]]\n\nCaused by op 'softmax_cross_entropy_loss/xentropy', defined at:\n  File \"//anaconda/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"//anaconda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"//anaconda/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"//anaconda/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"//anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-f5e691258d88>\", line 9, in <module>\n    loss = tf.losses.softmax_cross_entropy(y, y_hat)\n  File \"//anaconda/lib/python3.5/site-packages/tensorflow/python/ops/losses/losses_impl.py\", line 529, in softmax_cross_entropy\n    name=\"xentropy\")\n  File \"//anaconda/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 1617, in softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"//anaconda/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2265, in _softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"//anaconda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"//anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"//anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[379,3] labels_size=[379,1]\n\t [[Node: softmax_cross_entropy_loss/xentropy = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](softmax_cross_entropy_loss/Reshape, softmax_cross_entropy_loss/Reshape_1)]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        sess.run(training_op, feed_dict={X: X_train, y: y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
